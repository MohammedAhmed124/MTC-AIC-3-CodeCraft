# MTC-AIC-3 Winning pipeline 2025 ðŸ¥‡

This repository provides the complete, endâ€‘toâ€‘end winning pipeline for the MTC-AIC-3 EEG competition. It covers data loading, preprocessing, model training, and inference for both Motor Imagery (MI) and SSVEP tasks using the custom MTCFormer architecture.

---

## Project Structure
```
â”œâ”€â”€ data/ # Competition data
â”‚ â”œâ”€â”€ MI/ # MI trial files (.fif or raw)
â”‚ â”œâ”€â”€ SSVEP/ # SSVEP trial files
â”‚ â”œâ”€â”€ train.csv # Training labels and metadata
â”‚ â”œâ”€â”€ validation.csv # Validation labels and metadata
â”‚ â”œâ”€â”€ test.csv # Test metadata (no labels)
â”‚ â””â”€â”€ sample_submission.csv # Submission format example
â”œâ”€â”€ model/ # MTCFormer implementations and docs
â”‚ â”œâ”€â”€ MTCformerV2.py # VersionÂ 2 of the MTCFormer (used for ssvep)
â”‚ â”œâ”€â”€ MTCformerV3.py # VersionÂ 3 of the MTCFormer (used for MI)
â”‚ â””â”€â”€ README.md # Architecture details and diagram
â”œâ”€â”€ train/ # Training scripts
â”‚ â”œâ”€â”€ checkpoints/ # Saved model checkpoints
â”‚ â”œâ”€â”€ train_mi_model1.py # Train MI model variantÂ 
â”‚ â””â”€â”€ train_ssvep_model.py # Train SSVEP model
â”œâ”€â”€ inference/ # Inference pipeline
â”‚ â””â”€â”€ inference.py # Load models, run on data, save predictions
â”œâ”€â”€ utils/ # Utility modules
â”‚ â”œâ”€â”€ loader.py # Trial-level data loader (handles CSVâ†’tensor)
â”‚ â”œâ”€â”€ preprocessing.py # Filtering, normalization, bad-segment marking
â”‚ â”œâ”€â”€ augmentation.py # EEG augmentations: noise, shifting, warping, dropout
â”‚ â”œâ”€â”€ training.py # train_model() loop, schedulers, checkpointing
â”‚ â”œâ”€â”€ gradient_attack.py # FGSM adversarial training support
â”‚ â””â”€â”€ rank_ensemble.py # Rankâ€‘averaging ensembling utilities
â”œâ”€â”€ checkpoints/ # Topâ€‘level folder for final best checkpoints
â”œâ”€â”€ submission/ # Scripts/notebooks for preparing submissions
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # This file
```


## Main Components

### Data Loading  
`utils/loader.py` replaces the old CSVâ€‘toâ€‘FIF converter. It:
- Reads trial files CSV  
- Matches filenames to `train.csv` / `validation.csv`  
- Does feature engineering.
- filters trials automatically based on quality.
- returns a batched numpy array of shape (n_trials , n_channels , n_times)

### Preprocessing & Augmentation  
- **Preprocessing** (`utils/preprocessing.py`): bandâ€‘pass filtering, channel normalization etc.
- **Augmentation** (`utils/augmentation.py`): Gaussian noise, time shift, amplitude scaling, time warp, channel dropout.

### Model Definitions  
All architectures live in `model/`.  
- **MTCformerV2** and **MTCformerV3** implement convolutionalâ€‘attention blocks with sparse gating. V2 is used for ssvep while V3 performs better for MI.  
- See `model/README.md` for block diagrams and detailed layer descriptions.

### Training Loop  
`utils/training.py` provides `train_model()`, which handles:
- Loss computation (crossâ€‘entropy, domain/adversarial losses)  
- Optimizer & scheduler steps  
- Early stopping, checkpoint saving, TensorBoard logging  
- Adversarial training via `utils/gradient_attack.py` (FGSM variants)  
- Domain adaptation (subjectâ€‘ID loss) can be toggled or scheduled.

Example scripts:  
- `train/train_mi_model1.py` (MI variant 1)  
- `train/train_ssvep_model.py` (SSVEP)

### Inference & Submission  
`inference/inference.py` loads saved checkpoints, runs on validation or test sets, and writes `submission.csv`. You can choose the â€œbestâ€ checkpoints or most recent snapshots via commandâ€‘line flags.


---

## Getting Started

1. **Install dependencies** (tested on PythonÂ 3.10):  
   ```bash
   conda create -n eeg_env python=3.10 -y
   conda activate eeg_env
   pip install -r requirements.txt
   ```


##  Train Models

You can either train all models fully on the complete dataset or quickly test the training pipeline on a small subset.

### ðŸ”¹ Option 1: Full Training

Run the full training loop for each model:

```bash
python train/train_mi_model1.py
python train/train_ssvep_model.py
```
### ðŸ”¹Option 2: Test the Training Pipeline  
   Run a minimal version of the pipeline using only the first 50 samples.  
   Useful for debugging or verifying that the pipeline runs correctly.

   ```bash
   python train/train_mi_model1.py --test_pipeline
   python train/train_ssvep_model.py --test_pipeline
   ```

   > **Note:** This mode is not intended for meaningful training or performance evaluation. It is only for verifying that the pipeline executes correctly on a small subset of the data.

## Run inference

   By default, inference will use the best model checkpoints. If you want to test models from scratch or use the most recently generated checkpoints, you can pass the `--predict_on_best_models` argument as `False`:

   ```sh
   python inference/inference.py
   # or, to use non-best checkpoints:
   python inference/inference.py --predict_on_best_models False
   ```
   **to make predictions with a new test dataset. please replace the files related to older test set with the newer test set.**

   The output will be saved as `submission.csv` (or `submission_regenerated_(non_best).csv` if using non-best checkpoints or freshly trained models).


##  **Computational Environment**

This project was developed and tested under the following setup:

- **Operating System:** Ubuntu 22.04 LTS  
- **Python Version:** 3.10.8  
- **Environment Manager:** Conda  
- **System RAM:** 32 GB  
- **GPU:** NVIDIA RTX 4070 (12 GB VRAM)  
- **CUDA Version:** 12.6  
- **cuDNN Version:** 9.5.1  

---