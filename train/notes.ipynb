{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53af8f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys , os\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Project Path Setup\n",
    "#    - Add project root to Python path for consistent imports\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append( \"..\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "#  Core Imports\n",
    "#   - Model.MTCFormer\n",
    "#   - data extractors: extract_data,extract_subject_labels\n",
    "#   - training utils: predict\n",
    "#   - augmentation: augment_data\n",
    "#   - datasets: The custom EEGDataset\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "from model.MTCformerV3 import MTCFormer\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Adam\n",
    "from utils.extractors import extract_data,extract_subject_labels\n",
    "from utils.preprocessing import preprocess_data,preprocess_one_file\n",
    "from utils.augmentation import augment_data\n",
    "from utils.training import  predict\n",
    "from utils.CustomDataset import EEGDataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b20f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data, This may take a while... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2217it [00:15, 144.49it/s]\n",
      "47it [00:00, 219.61it/s]\n",
      "50it [00:00, 240.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation.... Wrapping preprocessed data inside tensor datasets....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_FIF_DIR = \"../data_fif\"\n",
    "\n",
    "\n",
    "test_file_paths_mi = glob.glob(os.path.join(DATA_FIF_DIR, \"test/MI/*.fif\"))\n",
    "train_file_paths_mi = glob.glob(os.path.join(DATA_FIF_DIR, \"train/MI/*.fif\"))\n",
    "val_file_paths_mi = glob.glob(os.path.join(DATA_FIF_DIR, \"validation/MI/*.fif\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mapping_mi = {\n",
    "    \"Left\":0,\n",
    "    \"Right\":1\n",
    "}   \n",
    "\n",
    "test_data_mi , test_labels_mi , ids_mi = extract_data(test_file_paths_mi , return_id = True)\n",
    "train_data_mi , train_labels_mi , ids = extract_data(train_file_paths_mi , return_id = True)\n",
    "val_data_mi , val_labels_mi , ids = extract_data(val_file_paths_mi , return_id = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_labels_mi_mapped = np.array([mapping_mi[x] for x in train_labels_mi])\n",
    "val_labels_mi_mapped = np.array([mapping_mi[x] for x in val_labels_mi])\n",
    "\n",
    "\n",
    "train_subject_labels = extract_subject_labels(train_data_mi)\n",
    "val_subject_labels = extract_subject_labels(val_data_mi)\n",
    "test_subject_labels = extract_subject_labels(test_data_mi)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# [Optional] Test Pipeline Mode: --test_pipeline\n",
    "#\n",
    "#    - When this flag is passed, the script enables a lightweight debug mode\n",
    "#      intended for fast testing and development.\n",
    "#\n",
    "#    - Instead of using the full dataset, it truncates the number of samples\n",
    "#      from each split train to only the **first 50 trials**.\n",
    "#\n",
    "#    - This affects:\n",
    "#        - Raw EEG data (`train_data_mi`, etc.)\n",
    "#        - Corresponding labels (`train_labels_mi_mapped`, etc.)\n",
    "#        - Subject ID labels (`train_subject_labels`, etc.)\n",
    "#\n",
    "#    - This mode is useful for verifying pipeline correctness quickly, without\n",
    "#      waiting for full data to load or process.\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "from utils.preprocessing import preprocess_data,preprocess_one_file\n",
    "print(\"Preprocessing data, This may take a while... \",end = \"\\n\\n\")\n",
    "\n",
    "\n",
    "cols_to_pick = [\n",
    "        'C3',\n",
    "        'C4',\n",
    "        'CZ',\n",
    "        'FZ',\n",
    "        'Acc_norm',\n",
    "        'gyro_norm',\n",
    "        'Validation'\n",
    "          ]\n",
    "\n",
    "params = {\n",
    "    \"cols_to_pick\":cols_to_pick,\n",
    "    \"l_freq\": 6,\n",
    "    \"h_freq\": 30,\n",
    "    \"notch_freqs\": [50, 100],\n",
    "    \"notch_width\": 1.0,\n",
    "    \"window_size\": 600,\n",
    "    \"window_stride\": 35\n",
    "}\n",
    "train_data,weights_train,windowed_train_labels,subject_label_train_, WINDOW_LEN = preprocess_data(\n",
    "    train_data_mi,\n",
    "    labels =train_labels_mi_mapped,\n",
    "    subject_labels = train_subject_labels,\n",
    "    preprocess_func=preprocess_one_file,\n",
    "    params = params,\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "\n",
    "val_data,weights_val,windowed_val_labels,subject_label_val_, WINDOW_LEN = preprocess_data(\n",
    "    val_data_mi,\n",
    "    labels = val_labels_mi_mapped,\n",
    "    subject_labels = val_subject_labels,\n",
    "    preprocess_func=preprocess_one_file,\n",
    "    params = params,\n",
    "    n_jobs=4\n",
    ")\n",
    "test_data,weights_test, _ ,subject_label_test_, WINDOW_LEN= preprocess_data(\n",
    "    test_data_mi,\n",
    "    labels = test_labels_mi,\n",
    "    subject_labels = test_subject_labels,\n",
    "    preprocess_func=preprocess_one_file,\n",
    "    params = params,\n",
    "    n_jobs=4\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. Convert preprocessed EEG windows into PyTorch-ready format\n",
    "#\n",
    "#    This stage converts numpy arrays from preprocessing into torch Tensors\n",
    "#    with correct dtypes and wraps them into PyTorch-compatible Datasets and\n",
    "#    DataLoaders. This makes the data pipeline ready for training.\n",
    "#\n",
    "#    Steps:\n",
    "#    -------------------------------------------------------------------------\n",
    "#    1. **Torch Conversion**:\n",
    "#       - Input data (EEG windows) is cast to `torch.float32`.\n",
    "#       - Labels and subject IDs are cast to `torch.long` (required for loss).\n",
    "#       - Sample weights are cast to `torch.float32` for possible loss weighting.\n",
    "#\n",
    "#    2. **Test Data Handling**:\n",
    "#       - Since test labels are unknown, placeholder zeros are used for compatibility.\n",
    "#\n",
    "#    3. **Custom Dataset**:\n",
    "#       - We use a custom `EEGDataset` class that wraps:\n",
    "#           - EEG windows\n",
    "#           - Sample weights\n",
    "#           - Class labels\n",
    "#           - Subject labels (for subject-level analysis)\n",
    "#       - Optional online data augmentation (enabled for training only).\n",
    "#\n",
    "#    4. **DataLoaders**:\n",
    "#       - Train loader uses batching and shuffling for training.\n",
    "#       - Val and Test loaders load the full set in one batch for deterministic evaluation.\n",
    "#\n",
    "#    5. **Device Setup**:\n",
    "#       - Automatically selects GPU (`cuda`) if available, otherwise falls back to CPU.\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "from utils.CustomDataset import EEGDataset\n",
    "from utils.augmentation import augment_data\n",
    "\n",
    "\n",
    "print(\"Data Preparation.... Wrapping preprocessed data inside tensor datasets....\",end = \"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "batch_size=100\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors with correct dtypes\n",
    "orig_labels_val_torch = torch.from_numpy(val_labels_mi_mapped).to(torch.long) # Original labels for validation aggregation\n",
    "\n",
    "train_mi_torch = torch.from_numpy(train_data).to(torch.float32)\n",
    "train_mi_labels_torch = torch.from_numpy(windowed_train_labels).to(torch.long)\n",
    "weights_train_torch = torch.from_numpy(weights_train).to(torch.float32) # Ensure float32\n",
    "train_mi_torch_subject = torch.from_numpy(subject_label_train_).to(torch.long)\n",
    "\n",
    "\n",
    "val_mi_torch = torch.from_numpy(val_data).to(torch.float32)\n",
    "val_mi_labels_torch = torch.from_numpy(windowed_val_labels).to(torch.long)\n",
    "weights_val_torch = torch.from_numpy(weights_val).to(torch.float32) # Ensure float32\n",
    "val_mi_torch_subject = torch.from_numpy(subject_label_val_).to(torch.long)\n",
    "\n",
    "test_mi_torch = torch.from_numpy(test_data).to(torch.float32)\n",
    "weights_test_torch = torch.from_numpy(weights_test).to(torch.float32)\n",
    "test_labels_placeholder = torch.zeros(test_mi_torch.shape[0], dtype=torch.long)\n",
    "test_mi_torch_subject = torch.from_numpy(subject_label_test_).to(torch.long)\n",
    "\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = EEGDataset(train_mi_torch, weights_train_torch, train_mi_labels_torch , train_mi_torch_subject,augment=True,augmentation_func=augment_data)\n",
    "val_dataset = EEGDataset(val_mi_torch, weights_val_torch, val_mi_labels_torch , val_mi_torch_subject)\n",
    "test_dataset = EEGDataset(test_mi_torch, weights_test_torch, test_labels_placeholder , test_mi_torch_subject)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False) # Full batch for validation\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False) # Full batch for test\n",
    "\n",
    "\n",
    "device_to_work_on = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_to_work_on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6500786f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mohammed_ahmed/MTC_REPO/train'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5170b97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46184656, 0.53815347],\n",
       "       [0.5045754 , 0.4954247 ],\n",
       "       [0.543059  , 0.45694107],\n",
       "       ...,\n",
       "       [0.49263743, 0.50736266],\n",
       "       [0.4024053 , 0.59759474],\n",
       "       [0.46077135, 0.5392287 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mi_1 = MTCFormer(depth=2,\n",
    "                    kernel_size=5,\n",
    "                    n_times=600,\n",
    "                    chs_num=7,\n",
    "                    eeg_ch_nums=4,\n",
    "                    class_num=2,\n",
    "                    class_num_domain=30,\n",
    "                    modulator_dropout=0.3,\n",
    "                    mid_dropout=0.5,\n",
    "                    output_dropout=0.5,\n",
    "                    weight_init_mean=0,\n",
    "                    weight_init_std=0.5,\n",
    "                    ).to(device)\n",
    "\n",
    "\n",
    "checkpoint_dicetory = \"../\"\n",
    "optimizer = Adam(model_mi_1.parameters(), lr=0.002)\n",
    "\n",
    "checkpoint_path = os.path.join(\n",
    "    checkpoint_dicetory,\n",
    "    \"checkpoints\",\n",
    "    \"model_1_mi_checkpoint\",\n",
    "    \"best_model_.pth\"\n",
    "    )\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "\n",
    "model_mi_1.load_state_dict(checkpoint['model_state_dict'] , strict=False)\n",
    "preds_mi_one = predict(\n",
    "    model_mi_1,\n",
    "    window_len=WINDOW_LEN,\n",
    "    loader=train_loader,\n",
    "    num_samples_to_predict=2217,\n",
    "    device = device,\n",
    "    probability=True\n",
    "    )\n",
    "preds_mi_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53c37797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47386113, 0.52613884],\n",
       "       [0.51480097, 0.485199  ],\n",
       "       [0.49435315, 0.5056469 ],\n",
       "       ...,\n",
       "       [0.5179802 , 0.4820198 ],\n",
       "       [0.48719618, 0.51280373],\n",
       "       [0.5185388 , 0.48146117]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_mi_two = MTCFormer(depth=2,\n",
    "                    kernel_size=5,\n",
    "                    n_times=600,\n",
    "                    chs_num=7,\n",
    "                    eeg_ch_nums=4,\n",
    "                    class_num=2,\n",
    "                    class_num_domain=30,\n",
    "                    modulator_dropout=0.3,\n",
    "                    mid_dropout=0.5,\n",
    "                    output_dropout=0.5,\n",
    "                    weight_init_mean=0,\n",
    "                    weight_init_std=0.5,\n",
    "                    ).to(device)\n",
    "\n",
    "\n",
    "checkpoint_dicetory = \"../\"\n",
    "optimizer = Adam(model_mi_two.parameters(), lr=0.002)\n",
    "\n",
    "checkpoint_path = os.path.join(\n",
    "    checkpoint_dicetory,\n",
    "    \"checkpoints\",\n",
    "    \"model_2_mi_checkpoint\",\n",
    "    \"best_model_.pth\"\n",
    "    )\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "\n",
    "model_mi_two.load_state_dict(checkpoint['model_state_dict'] , strict=False)\n",
    "\n",
    "preds_mi_two = predict(\n",
    "    model_mi_two,\n",
    "    window_len=WINDOW_LEN,\n",
    "    loader=train_loader,\n",
    "    num_samples_to_predict=2217,\n",
    "    device = device,\n",
    "    probability=True\n",
    "    )\n",
    "preds_mi_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0cbb966a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70018483, -0.70018475],\n",
       "       [-0.23019393,  0.23019185],\n",
       "       [ 0.80687607, -0.80687655],\n",
       "       [ 0.09439401, -0.0943943 ],\n",
       "       [-0.41423813,  0.41423826],\n",
       "       [-0.715663  ,  0.71566212],\n",
       "       [ 0.49167994, -0.4916792 ],\n",
       "       [-1.60755996,  1.60756591],\n",
       "       [ 0.14777895, -0.14777832],\n",
       "       [-0.84310176,  0.84310219],\n",
       "       [-0.36593847,  0.3659389 ],\n",
       "       [-0.48097119,  0.48097256],\n",
       "       [ 0.88314872, -0.88314814],\n",
       "       [ 0.03737948, -0.03738001],\n",
       "       [-1.02151726,  1.02151898],\n",
       "       [ 0.1684108 , -0.16841391],\n",
       "       [ 0.48514855, -0.48514831],\n",
       "       [-0.2830423 ,  0.28304226],\n",
       "       [-0.08771035,  0.08771143],\n",
       "       [ 1.06888014, -1.0688804 ],\n",
       "       [ 0.10846223, -0.10845999],\n",
       "       [-0.96520314,  0.96520359],\n",
       "       [-0.85641167,  0.85641142],\n",
       "       [-0.55816974,  0.55816944],\n",
       "       [-0.29796649,  0.29796667],\n",
       "       [-0.45401928,  0.45402072],\n",
       "       [-1.59632829,  1.59632855],\n",
       "       [-0.32450565,  0.32450518],\n",
       "       [ 0.65894676, -0.65894695],\n",
       "       [-0.10565768,  0.10565552],\n",
       "       [-0.50624895,  0.50624794],\n",
       "       [ 0.38977893, -0.38977756],\n",
       "       [-0.81154932,  0.81154986],\n",
       "       [-0.08271468,  0.08271426],\n",
       "       [ 0.61050744, -0.6105086 ],\n",
       "       [-0.18179067,  0.18179038],\n",
       "       [-1.05442926,  1.05442952],\n",
       "       [-0.80030937,  0.80030865],\n",
       "       [ 0.30591104, -0.30591149],\n",
       "       [-0.54661631,  0.54661644],\n",
       "       [ 0.11571958, -0.11571991],\n",
       "       [-0.78213705,  0.78213718],\n",
       "       [ 0.43024617, -0.43024577],\n",
       "       [ 0.35033721, -0.35033938],\n",
       "       [ 1.03053632, -1.03053669],\n",
       "       [-0.26754946,  0.26754946],\n",
       "       [ 0.28173795, -0.28173872],\n",
       "       [-0.5381192 ,  0.53811888],\n",
       "       [-0.19107867,  0.19107926],\n",
       "       [-0.0517598 ,  0.05175904]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_1 = np.array([\n",
    "[0.53246975 ,0.46753022],\n",
    " [0.48687148, 0.51312846],\n",
    " [0.5387039  ,0.46129608],\n",
    " [0.5021071,  0.49789286],\n",
    " [0.47704634, 0.5229537 ],\n",
    " [0.46221194 ,0.53778803],\n",
    " [0.52266014 ,0.4773399 ],\n",
    " [0.42057058, 0.57942945],\n",
    " [0.50525504, 0.494745  ],\n",
    " [0.45534346, 0.5446566 ],\n",
    " [0.47970426 ,0.5202958 ],\n",
    " [0.4733704 , 0.5266297 ],\n",
    " [0.5423661 , 0.45763397],\n",
    " [0.49935672 ,0.50064325],\n",
    " [0.4460962 , 0.5539039 ],\n",
    " [0.5064874,  0.49351254],\n",
    " [0.5220652 , 0.4779348 ],\n",
    " [0.48356584, 0.51643413],\n",
    " [0.49317035 ,0.5068297 ],\n",
    " [0.55157775 ,0.44842222],\n",
    " [0.5027857 , 0.49721432],\n",
    " [0.44819015 ,0.55180985],\n",
    " [0.45454434 ,0.54545563],\n",
    " [0.46888864 ,0.53111136],\n",
    " [0.4830007 , 0.5169993 ],\n",
    " [0.47482154, 0.5251785 ],\n",
    " [0.42132378, 0.5786762 ],\n",
    " [0.48184648 ,0.5181535 ],\n",
    " [0.530921 ,  0.469079  ],\n",
    " [0.4922824 , 0.50771755],\n",
    " [0.47214556, 0.52785444],\n",
    " [0.5168218  ,0.48317823],\n",
    " [0.4571302 , 0.5428698 ],\n",
    " [0.4934551 , 0.5065449 ],\n",
    " [0.52833664 ,0.47166333],\n",
    " [0.4886873 , 0.5113127 ],\n",
    " [0.444473 ,  0.555527  ],\n",
    " [0.4575885 , 0.54241145],\n",
    " [0.51342475 ,0.48657525],\n",
    " [0.46953878 ,0.5304612 ],\n",
    " [0.5031684 , 0.4968316 ],\n",
    " [0.45879114 ,0.54120886],\n",
    " [0.5187844  ,0.4812156 ],\n",
    " [0.5151648 , 0.48483512],\n",
    " [0.54893726, 0.4510627 ],\n",
    " [0.4846798 , 0.5153202 ],\n",
    " [0.51223046, 0.4877695 ],\n",
    " [0.47033954, 0.52966046],\n",
    " [0.48824993, 0.5117501 ],\n",
    " [0.49464935, 0.5053506 ]])\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Fit separate transformers per column\n",
    "qt_neg = QuantileTransformer(output_distribution='normal').fit(preds_mi_one[:, 0].reshape(-1, 1))\n",
    "qt_pos = QuantileTransformer(output_distribution='normal').fit(preds_mi_one[:, 1].reshape(-1, 1))\n",
    "\n",
    "# Transform new data similarly:\n",
    "X_transformed_1 = np.zeros_like(test_preds_1)\n",
    "X_transformed_1[:, 0] = qt_neg.transform(test_preds_1[:, 0].reshape(-1, 1)).flatten()\n",
    "X_transformed_1[:, 1] = qt_pos.transform(test_preds_1[:, 1].reshape(-1, 1)).flatten()\n",
    "X_transformed_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797d4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51177919, 0.48822046],\n",
       "       [0.1125957 , 0.88740253],\n",
       "       [0.4727341 , 0.52726561],\n",
       "       [0.84920063, 0.15079939],\n",
       "       [0.22328272, 0.77672153],\n",
       "       [0.39736489, 0.60263307],\n",
       "       [0.58940958, 0.41059441],\n",
       "       [0.15306612, 0.84693386],\n",
       "       [0.74182581, 0.25817431],\n",
       "       [0.39337131, 0.60662904],\n",
       "       [0.47508796, 0.52491217],\n",
       "       [0.31232081, 0.68767892],\n",
       "       [0.79642854, 0.20357154],\n",
       "       [0.94961244, 0.05038734],\n",
       "       [0.02834251, 0.97165711],\n",
       "       [0.83202696, 0.16797312],\n",
       "       [0.95059065, 0.04940945],\n",
       "       [0.54627801, 0.45372281],\n",
       "       [0.57872756, 0.42127252],\n",
       "       [0.91493001, 0.08507044],\n",
       "       [0.45662696, 0.5433736 ],\n",
       "       [0.0680805 , 0.93191968],\n",
       "       [0.33676808, 0.66323315],\n",
       "       [0.07097424, 0.92902552],\n",
       "       [0.58180376, 0.41819575],\n",
       "       [0.12896415, 0.8710358 ],\n",
       "       [0.06047154, 0.9395287 ],\n",
       "       [0.40651265, 0.59348773],\n",
       "       [0.74809399, 0.25190468],\n",
       "       [0.19249875, 0.80750215],\n",
       "       [0.29232009, 0.70767958],\n",
       "       [0.91812723, 0.08187285],\n",
       "       [0.03985482, 0.96014525],\n",
       "       [0.79542511, 0.20457492],\n",
       "       [0.12035211, 0.87964838],\n",
       "       [0.50075431, 0.49924557],\n",
       "       [0.38074009, 0.61926063],\n",
       "       [0.43321104, 0.56678853],\n",
       "       [0.82817824, 0.17182174],\n",
       "       [0.76571176, 0.23428865],\n",
       "       [0.45098567, 0.54901239],\n",
       "       [0.78618927, 0.21381051],\n",
       "       [0.32241101, 0.67758963],\n",
       "       [0.92675096, 0.07324878],\n",
       "       [0.63850567, 0.36149426],\n",
       "       [0.91945866, 0.0805424 ],\n",
       "       [0.74077359, 0.25922698],\n",
       "       [0.10148648, 0.89851302],\n",
       "       [0.52033136, 0.47966755],\n",
       "       [0.39531002, 0.60468975]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_2 = np.array([\n",
    "[0.5036396  ,0.49636036],\n",
    " [0.4728651 , 0.52713484],\n",
    " [0.5006888  ,0.49931118],\n",
    " [0.5313396 , 0.46866038],\n",
    " [0.48304752 ,0.5169525 ],\n",
    " [0.49555388 ,0.504446  ],\n",
    " [0.50834763, 0.49165243],\n",
    " [0.4771689 , 0.5228311 ],\n",
    " [0.5203398 , 0.47966024],\n",
    " [0.495307  , 0.50469303],\n",
    " [0.5008955 , 0.49910453],\n",
    " [0.48937204 ,0.5106279 ],\n",
    " [0.5252463 , 0.47475374],\n",
    " [0.5483076 , 0.45169237],\n",
    " [0.45992485, 0.5400751 ],\n",
    " [0.5295104 , 0.47048965],\n",
    " [0.54884744, 0.45115265],\n",
    " [0.5056256 , 0.4943744 ],\n",
    " [0.5074791  ,0.49252093],\n",
    " [0.54100263, 0.4589974 ],\n",
    " [0.49924478, 0.50075525],\n",
    " [0.46759537 ,0.53240466],\n",
    " [0.491207  , 0.50879306],\n",
    " [0.46828505 ,0.5317149 ],\n",
    " [0.5076705 , 0.49232942],\n",
    " [0.4747552,  0.5252448 ],\n",
    " [0.46640074, 0.5335993 ],\n",
    " [0.49615887, 0.50384116],\n",
    " [0.5209354 , 0.47906458],\n",
    " [0.48120984 ,0.5187902 ],\n",
    " [0.4874002  ,0.51259977],\n",
    " [0.54170877, 0.45829126],\n",
    " [0.46296924, 0.53703076],\n",
    " [0.525115 ,  0.47488502],\n",
    " [0.47401354 ,0.5259865 ],\n",
    " [0.50283843, 0.49716154],\n",
    " [0.4943745 , 0.50562555],\n",
    " [0.49801394 ,0.501986  ],\n",
    " [0.52885187, 0.47114813],\n",
    " [0.52234006, 0.47766   ],\n",
    " [0.4989587 , 0.50104123],\n",
    " [0.52421755, 0.47578242],\n",
    " [0.4901222 , 0.50987786],\n",
    " [0.5432616  ,0.45673832],\n",
    " [0.51199526, 0.48800474],\n",
    " [0.5419697  ,0.45803037],\n",
    " [0.5202589 , 0.4797411 ],\n",
    " [0.4716455 , 0.52835447],\n",
    " [0.5039931 , 0.49600688],\n",
    " [0.49536097 ,0.504639  ]])\n",
    "# Fit separate transformers per column\n",
    "qt_neg = QuantileTransformer(output_distribution='normal').fit(preds_mi_two[:, 0].reshape(-1, 1))\n",
    "qt_pos = QuantileTransformer(output_distribution='normal').fit(preds_mi_two[:, 1].reshape(-1, 1))\n",
    "\n",
    "# Transform new data similarly:\n",
    "X_transformed_2 = np.zeros_like(test_preds_2)\n",
    "X_transformed_2[:, 0] = qt_neg.transform(test_preds_2[:, 0].reshape(-1, 1)).flatten()\n",
    "X_transformed_2[:, 1] = qt_pos.transform(test_preds_2[:, 1].reshape(-1, 1)).flatten()\n",
    "\n",
    "X_transformed_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ce502c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73979391, 0.26020595],\n",
       "       [0.39557187, 0.60442731],\n",
       "       [0.7788764 , 0.2211235 ],\n",
       "       [0.51689798, 0.48310194],\n",
       "       [0.32462526, 0.67537494],\n",
       "       [0.22617865, 0.77382069],\n",
       "       [0.67370283, 0.32629757],\n",
       "       [0.04913542, 0.95086468],\n",
       "       [0.53959609, 0.46040388],\n",
       "       [0.18878428, 0.81121621],\n",
       "       [0.34123828, 0.65876206],\n",
       "       [0.29952245, 0.70047809],\n",
       "       [0.79959989, 0.20040027],\n",
       "       [0.49433106, 0.50566873],\n",
       "       [0.14160796, 0.85839237],\n",
       "       [0.5498274 , 0.45017107],\n",
       "       [0.67054742, 0.32945233],\n",
       "       [0.37047389, 0.62952592],\n",
       "       [0.44698653, 0.55301371],\n",
       "       [0.84460897, 0.15539092],\n",
       "       [0.52271737, 0.47728276],\n",
       "       [0.15379278, 0.84620743],\n",
       "       [0.18254559, 0.81745394],\n",
       "       [0.2712957 , 0.72870435],\n",
       "       [0.36513338, 0.63486676],\n",
       "       [0.30870504, 0.69129529],\n",
       "       [0.05050475, 0.94949523],\n",
       "       [0.35621574, 0.64378371],\n",
       "       [0.72793551, 0.27206441],\n",
       "       [0.44061884, 0.55938074],\n",
       "       [0.2911605 , 0.70883911],\n",
       "       [0.63342646, 0.36657389],\n",
       "       [0.19774719, 0.8022527 ],\n",
       "       [0.44934975, 0.55065028],\n",
       "       [0.71283985, 0.28716005],\n",
       "       [0.41088946, 0.58911099],\n",
       "       [0.13416498, 0.8658351 ],\n",
       "       [0.20026443, 0.79973534],\n",
       "       [0.6068989 , 0.39310116],\n",
       "       [0.27461519, 0.72538475],\n",
       "       [0.52599075, 0.47400915],\n",
       "       [0.20608532, 0.79391477],\n",
       "       [0.64961474, 0.3503856 ],\n",
       "       [0.62075647, 0.37924276],\n",
       "       [0.83320389, 0.16679595],\n",
       "       [0.3780905 , 0.62190945],\n",
       "       [0.59657671, 0.40342285],\n",
       "       [0.27804492, 0.72195494],\n",
       "       [0.40802604, 0.5919739 ],\n",
       "       [0.45974468, 0.5402548 ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_transform = QuantileTransformer(output_distribution='uniform').fit(preds_mi_one.reshape(-1, 1))\n",
    "transformed_data_1 = q_transform.transform(test_preds_1.reshape(-1,1)).reshape(-1,2)\n",
    "transformed_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aed1ab9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55198052, 0.44801877],\n",
       "       [0.14954949, 0.85044856],\n",
       "       [0.50777743, 0.49222223],\n",
       "       [0.88725688, 0.11274308],\n",
       "       [0.25980571, 0.74019442],\n",
       "       [0.43628793, 0.56370995],\n",
       "       [0.62277653, 0.37722481],\n",
       "       [0.18950199, 0.8104978 ],\n",
       "       [0.78384999, 0.21614999],\n",
       "       [0.43234563, 0.5676541 ],\n",
       "       [0.51092002, 0.48907981],\n",
       "       [0.34520355, 0.65479507],\n",
       "       [0.83365697, 0.16634303],\n",
       "       [0.97066866, 0.02933115],\n",
       "       [0.05894386, 0.94105598],\n",
       "       [0.87197925, 0.12802068],\n",
       "       [0.97152461, 0.02847547],\n",
       "       [0.58294703, 0.41705482],\n",
       "       [0.61115529, 0.3888454 ],\n",
       "       [0.94505385, 0.05494662],\n",
       "       [0.49141833, 0.50858189],\n",
       "       [0.10728984, 0.89271019],\n",
       "       [0.37096731, 0.62903336],\n",
       "       [0.11012818, 0.88987159],\n",
       "       [0.61339668, 0.38660211],\n",
       "       [0.16635202, 0.83364774],\n",
       "       [0.09749454, 0.90250535],\n",
       "       [0.44495322, 0.55504616],\n",
       "       [0.78870371, 0.21129598],\n",
       "       [0.23378939, 0.76621144],\n",
       "       [0.32353217, 0.67646763],\n",
       "       [0.94889803, 0.05110222],\n",
       "       [0.07537   , 0.92463006],\n",
       "       [0.83284903, 0.16715093],\n",
       "       [0.15862764, 0.84137289],\n",
       "       [0.53891804, 0.46108178],\n",
       "       [0.4170589 , 0.58294499],\n",
       "       [0.4721083 , 0.52789102],\n",
       "       [0.86666786, 0.13333252],\n",
       "       [0.80463352, 0.19536695],\n",
       "       [0.48733756, 0.51266089],\n",
       "       [0.82337399, 0.17662597],\n",
       "       [0.35806029, 0.64194002],\n",
       "       [0.95476102, 0.04523867],\n",
       "       [0.67020937, 0.32979096],\n",
       "       [0.9499353 , 0.05006509],\n",
       "       [0.78209602, 0.21790424],\n",
       "       [0.13891075, 0.86108891],\n",
       "       [0.55785828, 0.44214116],\n",
       "       [0.43350438, 0.56649549]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_transform = QuantileTransformer(output_distribution='uniform').fit(preds_mi_two.reshape(-1, 1))\n",
    "transformed_data_2 = q_transform.transform(test_preds_2.reshape(-1,1)).reshape(-1,2)\n",
    "transformed_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "43c89525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble = (X_transformed_2+X_transformed_1)/2\n",
    "\n",
    "preds_ensemble = np.argmax(ensemble,axis=1)\n",
    "preds_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "edbc5335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.86)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds_ensemble==old).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a465c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = np.array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
    "       0, 0, 0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4eb4c3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4939</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4948</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4945</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4920</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4921</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4937</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4906</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4919</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4922</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4912</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4902</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4903</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4934</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4944</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4941</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4949</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4950</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4940</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4913</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4928</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4933</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4905</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4925</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4916</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4918</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4924</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4917</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4927</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4942</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4910</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4929</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4930</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4911</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4901</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4947</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4926</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4938</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4932</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4923</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4909</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4904</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4946</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4931</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4908</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4907</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4914</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4943</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4936</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4935</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4915</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0   4939   Left\n",
       "1   4948  Right\n",
       "2   4945   Left\n",
       "3   4920   Left\n",
       "4   4921  Right\n",
       "5   4937  Right\n",
       "6   4906   Left\n",
       "7   4919  Right\n",
       "8   4922   Left\n",
       "9   4912  Right\n",
       "10  4902  Right\n",
       "11  4903  Right\n",
       "12  4934   Left\n",
       "13  4944   Left\n",
       "14  4941  Right\n",
       "15  4949   Left\n",
       "16  4950   Left\n",
       "17  4940  Right\n",
       "18  4913  Right\n",
       "19  4928   Left\n",
       "20  4933   Left\n",
       "21  4905  Right\n",
       "22  4925  Right\n",
       "23  4916  Right\n",
       "24  4918  Right\n",
       "25  4924  Right\n",
       "26  4917  Right\n",
       "27  4927  Right\n",
       "28  4942   Left\n",
       "29  4910  Right\n",
       "30  4929  Right\n",
       "31  4930   Left\n",
       "32  4911  Right\n",
       "33  4901   Left\n",
       "34  4947   Left\n",
       "35  4926  Right\n",
       "36  4938  Right\n",
       "37  4932  Right\n",
       "38  4923   Left\n",
       "39  4909  Right\n",
       "40  4904   Left\n",
       "41  4946  Right\n",
       "42  4931   Left\n",
       "43  4908   Left\n",
       "44  4907   Left\n",
       "45  4914   Left\n",
       "46  4943   Left\n",
       "47  4936  Right\n",
       "48  4935  Right\n",
       "49  4915  Right"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_mapping_mi = {v:k for k,v in mapping_mi.items()}\n",
    "preds_mi_csv = pd.DataFrame({\n",
    "    \"id\":ids_mi,\n",
    "    \"label\": pd.Series(preds_ensemble).map(inv_mapping_mi).values\n",
    "})\n",
    "\n",
    "preds_mi_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "65d4f877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 437.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4901</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4902</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4903</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4904</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4905</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4996</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4997</td>\n",
       "      <td>Forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4998</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4999</td>\n",
       "      <td>Backward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5000</td>\n",
       "      <td>Forward</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     label\n",
       "0   4901      Left\n",
       "1   4902     Right\n",
       "2   4903     Right\n",
       "3   4904      Left\n",
       "4   4905     Right\n",
       "..   ...       ...\n",
       "95  4996      Left\n",
       "96  4997   Forward\n",
       "97  4998     Right\n",
       "98  4999  Backward\n",
       "99  5000   Forward\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_paths_ssvep = glob.glob(os.path.join(DATA_FIF_DIR, \"test/SSVEP/*.fif\"))\n",
    "\n",
    "test_data_ssvep, test_labels_ssvep , ids_ssvep = extract_data(test_file_paths_ssvep , return_id = True)\n",
    "test_subject_labels = extract_subject_labels(test_data_ssvep)\n",
    "\n",
    "\n",
    "mapping_ssvep = {\n",
    "    \"Backward\":0,\n",
    "    \"Forward\":1,\n",
    "    \"Left\":2,\n",
    "    \"Right\":3\n",
    "}\n",
    "\n",
    "inv_mapping_ssvep = {\n",
    "    v:k for k,v in mapping_ssvep.items()\n",
    "}\n",
    "\n",
    "\n",
    "model_ssvep = MTCFormer(\n",
    "    depth=1,\n",
    "    kernel_size=10,\n",
    "    n_times=500,\n",
    "    chs_num=7,\n",
    "    eeg_ch_nums=4,\n",
    "    class_num=4,\n",
    "    class_num_domain=30,\n",
    "    modulator_kernel_size=10,\n",
    "    domain_dropout=0.7,\n",
    "    modulator_dropout=0.7,\n",
    "    mid_dropout=0.7,\n",
    "    output_dropout=0.7,\n",
    "    weight_init_std=0.05,\n",
    "    weight_init_mean=0.0,\n",
    ").to(device)\n",
    "\n",
    "optimizer = Adam(model_ssvep.parameters(), lr=0.002)\n",
    "\n",
    "checkpoint_path = os.path.join(\n",
    "    \"../\",\n",
    "    \"checkpoints\",\n",
    "    \"model_ssvep_checkpoint\",\n",
    "    \"best_model_.pth\"\n",
    "    )\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "\n",
    "model_ssvep.load_state_dict(checkpoint['model_state_dict'] , strict=False)\n",
    "\n",
    "\n",
    "cols_to_pick = [\n",
    "        'OZ',\n",
    "        'PO7',\n",
    "        'PO8',\n",
    "        'PZ',\n",
    "        'Acc_norm',\n",
    "        'gyro_norm',\n",
    "        'Validation'\n",
    "          ]\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"cols_to_pick\":cols_to_pick,\n",
    "    \"l_freq\": 8,\n",
    "    \"h_freq\": 14,\n",
    "    \"notch_freqs\": [50, 100],\n",
    "    \"notch_width\": 1.0,\n",
    "    \"window_size\": 500,\n",
    "    \"window_stride\": 50\n",
    "}\n",
    "\n",
    "test_data,weights_test, _ ,subject_label_test_, WINDOW_LEN= preprocess_data(\n",
    "    test_data_ssvep,\n",
    "    labels = test_labels_ssvep,\n",
    "    subject_labels = test_subject_labels,\n",
    "    preprocess_func=preprocess_one_file,\n",
    "    params = params,\n",
    "    n_jobs=4\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "weights_test_torch = torch.from_numpy(weights_test).to(torch.float32)\n",
    "test_ssvep_torch = torch.from_numpy(test_data).to(torch.float32)\n",
    "test_labels_placeholder = torch.zeros(test_ssvep_torch.shape[0], dtype=torch.long)\n",
    "test_ssvep_torch_subject = torch.from_numpy(subject_label_test_).to(torch.long)\n",
    "\n",
    "test_dataset = EEGDataset(\n",
    "    data_tensor=test_ssvep_torch,\n",
    "    weigths=weights_test_torch,\n",
    "    label_tensor=test_labels_placeholder,\n",
    "    subject_labels=test_ssvep_torch_subject\n",
    "    )\n",
    "\n",
    "test_loader   = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=len(test_dataset),\n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "final_preds_ssvep= predict(\n",
    "    model_ssvep,\n",
    "    window_len=WINDOW_LEN,\n",
    "    loader=test_loader,\n",
    "    num_samples_to_predict=50,\n",
    "    device = device,\n",
    "    probability=False,\n",
    "    num_classes=4\n",
    "    )\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "#  Final Submission Assembly\n",
    "#\n",
    "# - Convert SSVEP predictions to a DataFrame and map class indices to labels\n",
    "# - Concatenate MI and SSVEP prediction DataFrames\n",
    "# - Sort by ID and save as the final submission CSV\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "preds_ssvep_csv = pd.DataFrame({\n",
    "    \"id\":ids_ssvep,\n",
    "    \"label\": pd.Series(final_preds_ssvep).map(inv_mapping_ssvep).values\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "submission = pd.concat([\n",
    "    preds_mi_csv,\n",
    "    preds_ssvep_csv\n",
    "]).sort_values(\n",
    "    by=\"id\"\n",
    ").reset_index(\n",
    "    drop=True\n",
    ")\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "507f8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"quantile_ensemble_uniform_2.csv\" , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98780657",
   "metadata": {},
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Competition_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
