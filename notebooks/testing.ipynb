{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80259cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f93c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99bdc468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "WrappedModel                                            [32, 2]                   --\n",
       "├─MTCFormer: 1-1                                        [32, 2]                   --\n",
       "│    └─TemporalModulator: 2-1                           [32, 4, 600]              --\n",
       "│    │    └─Conv1d: 3-1                                 [32, 4, 600]              64\n",
       "│    │    └─ChannelWiseLayerNorm: 3-2                   [32, 4, 600]              8\n",
       "│    │    └─Dropout: 3-3                                [32, 4, 600]              --\n",
       "│    │    └─Sigmoid: 3-4                                [32, 4, 600]              --\n",
       "│    └─Conv1d: 2-2                                      [32, 8, 600]              40\n",
       "│    └─ChannelWiseLayerNorm: 2-3                        [32, 8, 600]              16\n",
       "│    └─GELU: 2-4                                        [32, 8, 600]              --\n",
       "│    └─Dropout: 2-5                                     [32, 8, 600]              --\n",
       "│    └─ConvolutionalAttention: 2-6                      [32, 8, 600]              --\n",
       "│    │    └─ModuleList: 3-5                             --                        363,328\n",
       "│    └─LearnablePooling: 2-7                            [32, 4, 300]              --\n",
       "│    │    └─Sequential: 3-6                             [32, 4, 300]              44\n",
       "│    │    └─Conv1d: 3-7                                 [32, 4, 300]              644\n",
       "│    │    └─ChannelWiseLayerNorm: 3-8                   [32, 4, 300]              8\n",
       "│    │    └─GELU: 3-9                                   [32, 4, 300]              --\n",
       "│    └─DomainClassifier: 2-8                            [32, 30]                  --\n",
       "│    │    └─Sequential: 3-10                            [32, 30]                  123,330\n",
       "│    └─Sequential: 2-9                                  [32, 2]                   --\n",
       "│    │    └─Flatten: 3-11                               [32, 1200]                --\n",
       "│    │    └─Dropout: 3-12                               [32, 1200]                --\n",
       "│    │    └─Linear: 3-13                                [32, 30]                  36,030\n",
       "│    │    └─LayerNorm: 3-14                             [32, 30]                  60\n",
       "│    │    └─GELU: 3-15                                  [32, 30]                  --\n",
       "│    │    └─Dropout: 3-16                               [32, 30]                  --\n",
       "│    │    └─Linear: 3-17                                [32, 2]                   62\n",
       "=========================================================================================================\n",
       "Total params: 523,634\n",
       "Trainable params: 523,634\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 31.54\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.54\n",
       "Forward/backward pass size (MB): 9.91\n",
       "Params size (MB): 2.09\n",
       "Estimated Total Size (MB): 12.54\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys ,os\n",
    "sys.path.append( \"..\")\n",
    "from model.MTCformerV3 import MTCFormer\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "\n",
    "class WrappedModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x, domain_lambda=0.0)[0]  # Only return task output for summary\n",
    "    \n",
    "\n",
    "model_former_curr = MTCFormer(\n",
    "    depth=1,\n",
    "    kernel_size=5,\n",
    "    n_times=600,\n",
    "    chs_num=7,\n",
    "    eeg_ch_nums=4,\n",
    "    class_num=2,\n",
    "    class_num_domain=30,\n",
    "    modulator_dropout=0.2,\n",
    "    mid_dropout=0.5,\n",
    "    output_dropout=0.5,\n",
    "    weight_init_mean=0,\n",
    "    weight_init_std=0.5,\n",
    "    pooler_kernel_size=20,\n",
    "    seed = 100,\n",
    ")\n",
    "\n",
    "model_former_curr = WrappedModel(model_former_curr)\n",
    "summary(model_former_curr , input_size=[32 , 7 , 600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb370218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool((None,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9734cdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MTCFormer(\n",
       "  (temporal_attention): TemporalModulator(\n",
       "    (sensor_conv): Conv1d(3, 4, kernel_size=(5,), stride=(1,), padding=same)\n",
       "    (sensor_norm): ChannelWiseLayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "    (sensor_dropout): Dropout(p=0.2, inplace=False)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (patch_conv): Conv1d(4, 8, kernel_size=(1,), stride=(1,), padding=same)\n",
       "  (patch_norm): ChannelWiseLayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "  (patch_act): GELU(approximate='none')\n",
       "  (patch_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (transformer): ConvolutionalAttention(\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvolutionalAttentionBlock(\n",
       "        (norm_1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "        (conv): Conv1d(8, 8, kernel_size=(5,), stride=(1,), padding=same)\n",
       "        (activation_1): GELU(approximate='none')\n",
       "        (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "        (norm_2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "        (feedforward): Linear(in_features=600, out_features=600, bias=True)\n",
       "        (activation_2): GELU(approximate='none')\n",
       "        (dropout_2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (learned_pooling): LearnablePooling(\n",
       "    (pooler_1): Conv1d(8, 4, kernel_size=(10,), stride=(2,))\n",
       "    (norm_1): ChannelWiseLayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "    (activation_1): GELU(approximate='none')\n",
       "    (pooler_2): Conv1d(4, 4, kernel_size=(5,), stride=(2,))\n",
       "    (norm_2): ChannelWiseLayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "    (activation_2): GELU(approximate='none')\n",
       "    (skip_proj): Sequential(\n",
       "      (0): Conv1d(8, 4, kernel_size=(1,), stride=(4,))\n",
       "      (1): ChannelWiseLayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (mlp_head): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=600, out_features=12, bias=True)\n",
       "    (3): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "    (4): GELU(approximate='none')\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=12, out_features=2, bias=True)\n",
       "  )\n",
       "  (domain_classifier): DomainClassifier(\n",
       "    (net): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Linear(in_features=600, out_features=180, bias=True)\n",
       "      (3): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
       "      (4): GELU(approximate='none')\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=180, out_features=30, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_former_curr = MTCFormer(\n",
    "    depth=1,\n",
    "    kernel_size=5,\n",
    "    n_times=600,\n",
    "    chs_num=7,\n",
    "    eeg_ch_nums=4,\n",
    "    class_num=2,\n",
    "    class_num_domain=30,\n",
    "    modulator_dropout=0.2,\n",
    "    mid_dropout=0.5,\n",
    "    output_dropout=0.5,\n",
    "    weight_init_mean=0,\n",
    "    weight_init_std=0.5,\n",
    "    seed = 100,\n",
    ")\n",
    "\n",
    "model_former_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab74b811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 8, 873, 128)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "# Example data: 10 signals, 8 channels, 1000 timepoints\n",
    "X = np.random.randn(10, 8, 1000)\n",
    "\n",
    "# Create sliding windows of size 128 with stride 1 (default)\n",
    "window_size = 128\n",
    "X_windowed = sliding_window_view(X, window_shape=window_size, axis=2)\n",
    "\n",
    "# X_windowed.shape: (10, 8, 1000 - 128 + 1, 128)\n",
    "print(X_windowed.shape)  # (10, 8, 873, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e7c2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8, 18, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_windowed = X_windowed[:, :, ::50, :]\n",
    "X_windowed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970aca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.randn(10, 8, 1000)  # [n_signals, channels, time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57a64321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([280, 8, 128])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "window_size = 128\n",
    "stride = 32\n",
    "\n",
    "X_unfolded = X.unfold(dimension=2, size=window_size, step=stride).permute(0,2,1,3).reshape(-1 , 8 , 128)\n",
    "# Shape: [10, 8, n_windows, 128]\n",
    "print(X_unfolded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b883d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0834, -1.5369, -0.5111,  ...,  0.1169,  0.8433, -0.2823],\n",
       "        [ 0.5323, -1.0056,  0.0369,  ...,  0.9354,  0.7785,  0.7830],\n",
       "        [-0.9183,  0.1634,  2.6049,  ..., -1.3368, -2.1676,  0.1507],\n",
       "        ...,\n",
       "        [-0.6156,  0.5981,  0.0175,  ...,  2.0049, -0.7799,  0.1091],\n",
       "        [-1.0664,  1.8076, -0.5650,  ...,  0.0146, -0.3809, -0.9579],\n",
       "        [-0.7578,  0.6202, -0.7500,  ..., -1.4003, -0.8852, -0.1490]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unfolded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f84cc8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0834, -1.5369, -0.5111,  ...,  0.1169,  0.8433, -0.2823],\n",
       "        [ 0.5323, -1.0056,  0.0369,  ...,  0.9354,  0.7785,  0.7830],\n",
       "        [-0.9183,  0.1634,  2.6049,  ..., -1.3368, -2.1676,  0.1507],\n",
       "        ...,\n",
       "        [-0.6156,  0.5981,  0.0175,  ...,  2.0049, -0.7799,  0.1091],\n",
       "        [-1.0664,  1.8076, -0.5650,  ...,  0.0146, -0.3809, -0.9579],\n",
       "        [-0.7578,  0.6202, -0.7500,  ..., -1.4003, -0.8852, -0.1490]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unfolded[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Competition_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
